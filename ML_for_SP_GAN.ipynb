{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML for SP PESIT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nidhin-koshy/ML_SP_GAN/blob/master/ML_for_SP_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyEZyKWIJIey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ba439efa-72a3-48c6-8ea9-08232535bff7"
      },
      "source": [
        "import os\n",
        "if(not os.path.exists(\"ML_SP_GAN\")):\n",
        "  ! git clone https://github.com/nidhin-koshy/ML_SP_GAN.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML_SP_GAN'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Total 61 (delta 0), reused 0 (delta 0), pack-reused 61\u001b[K\n",
            "Unpacking objects: 100% (61/61), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSxfuVp4Pas_",
        "colab_type": "code",
        "outputId": "1cb4e414-9900-4b1c-ed9c-ab365407cf0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! cd ML_SP_GAN && git pull "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky5M1KEJ620d",
        "colab_type": "code",
        "outputId": "c2431cf3-dccd-48e2-b3f2-0fc2f6a345ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1499
        }
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "import sys\n",
        "sys.path.append('ML_SP_GAN')\n",
        "from myFunctions import features_1 # myFunctions.py is available as part of the the Github repository.\n",
        "from myFunctions import features_2\n",
        "\n",
        "#Data set specific variables\n",
        "freq = 125\n",
        "dataleninsec = 8\n",
        "dataoffsetinsec = 2 \n",
        "numsampleswin = freq*dataleninsec\n",
        "\n",
        "data_dir_path = './ML_SP_GAN/ppg_test_data_csv/Training_data/' #'/content/gdrive/My Drive/ML_SP_PESIT/ml-course-code-may14/ml-course-code/ppg_test_data_csv/Training_data/'   #'../ppg_test_data_csv/Training_data/'\n",
        "\n",
        "train_set_02 = ['DATA_02_TYPE02.csv', 'DATA_04_TYPE02.csv', 'DATA_06_TYPE02.csv', 'DATA_08_TYPE02.csv', 'DATA_10_TYPE02.csv', 'DATA_12_TYPE02.csv', 'DATA_03_TYPE02.csv', 'DATA_05_TYPE02.csv', 'DATA_07_TYPE02.csv', 'DATA_09_TYPE02.csv', 'DATA_11_TYPE02.csv']\n",
        "#\n",
        "train_set_02_BPM = ['DATA_02_TYPE02_BPMtrace.csv', 'DATA_04_TYPE02_BPMtrace.csv', 'DATA_06_TYPE02_BPMtrace.csv', 'DATA_08_TYPE02_BPMtrace.csv', 'DATA_10_TYPE02_BPMtrace.csv', 'DATA_12_TYPE02_BPMtrace.csv', 'DATA_03_TYPE02_BPMtrace.csv', 'DATA_05_TYPE02_BPMtrace.csv', 'DATA_07_TYPE02_BPMtrace.csv', 'DATA_09_TYPE02_BPMtrace.csv', 'DATA_11_TYPE02_BPMtrace.csv']\n",
        "\n",
        "#train_set_02 = ['DATA_04_TYPE02.csv']\n",
        "#train_set_02_BPM = ['DATA_04_TYPE02_BPMtrace.csv']\n",
        "\n",
        "for file_ind in np.arange(0,len(train_set_02)):\n",
        "   #print train_set_02[file_ind]\n",
        "   #print train_set_02_BPM[file_ind]\n",
        "\n",
        "   filepath = data_dir_path+train_set_02[file_ind]\n",
        "   \n",
        "   #Load training data from a file\n",
        "   data = np.loadtxt(open(filepath, \"rb\"), delimiter=\",\")\n",
        "   \n",
        "   \n",
        "   datalen = data.shape[0]  #Total length of data\n",
        "   #Indexes to split a single array into matrix. A single BPM is computed over an interval of 8s (1000 samples). \n",
        "   #The next number over another 8s window starting at an offset of 2s (500 samples) from previous window\n",
        "\n",
        "   index_arr = np.arange(0, datalen-numsampleswin+1, freq*dataoffsetinsec)  \n",
        "   #print datalen #print index_arr.shape[0] #print index_arr\n",
        "\n",
        "   datax=np.zeros(shape=(index_arr.shape[0], numsampleswin, 6),dtype=np.float)\n",
        "   datax_pd=np.zeros(shape=(index_arr.shape[0], numsampleswin, 6),dtype=np.float)\n",
        "   temp = pd.read_csv(filepath)\n",
        "   temp.head()\n",
        "   for j in np.arange(0,6):\n",
        "    for i in range(index_arr.shape[0]) : datax[i,:,j] = data[index_arr[i]:numsampleswin+index_arr[i], j]\n",
        "        \n",
        "   \n",
        "   #For training we are ignoring the ECG signal as this signal is not available for test data. ECG output\n",
        "   #is available as _BPM.csv dataset\n",
        "   \n",
        "   #Use datax1 to compute features to be used in training\n",
        "   \n",
        "   datax1=np.zeros(shape=(index_arr.shape[0], numsampleswin, 5),dtype=np.float)\n",
        "   datax1=datax[:,:,1:6]\n",
        "   #j = 1 \n",
        "   #err = []\n",
        "   #for i in np.arange(0,148):\n",
        "   #  #err.append(sum(datax[i,:,j] - np.transpose(data[250*i:1000+250*i,j])))\n",
        "   #  err.append(sum(datax1[i,:,j] - np.transpose(data[250*i:1000+250*i,j+1])))\n",
        "   #print (\"Testing data matrix creation Error: \", sum(err))\n",
        "   \n",
        "   \n",
        "   #X = np.column_stack((np.ones([index_arr.shape[0],1], dtype=float), features_2(datax1)))\n",
        "   X = features_2(datax1)\n",
        "   X = normalize(X, norm='l2', axis=0, return_norm=False)\n",
        "   \n",
        "   if file_ind == 0: \n",
        "      X_aggregate = np.copy(X)\n",
        "   else:\n",
        "      X_aggregate = np.vstack((X_aggregate, X))\n",
        "   #print X.shape\n",
        "   #print X_aggregate.shape\n",
        "   #\n",
        "   \n",
        "   outfilepath = data_dir_path+train_set_02_BPM[file_ind]\n",
        "   #Load output training data from a file\n",
        "   outdata = np.loadtxt(open(outfilepath, \"rb\"), delimiter=\",\")\n",
        "\n",
        "   #print outdata.shape[0]\n",
        "   if file_ind == 0: \n",
        "      Y_aggregate = np.copy(outdata)\n",
        "   else:\n",
        "      #Y_aggregate = np.vstack((Y_aggregate, outdata))\n",
        "      Y_aggregate = np.hstack((Y_aggregate, outdata))\n",
        "\n",
        "\n",
        "#Split the data into train and cross-validate\n",
        "npts = 143 \n",
        "print (Y_aggregate.shape)\n",
        "print (X_aggregate.shape)\n",
        "X_train = X_aggregate[:-npts, :]\n",
        "X_test = X_aggregate[-npts:, :]\n",
        "Y_train = Y_aggregate[:-npts]\n",
        "Y_test = Y_aggregate[-npts:]\n",
        "\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(X_train, Y_train)\n",
        "pred_Y = regr.predict(X_test)\n",
        "\n",
        "\n",
        "#print('Variance score: %.2f' % r2_score(pred_Y, Y_test))\n",
        "\n",
        "#for i in np.arange(0,Y_test.shape[0]):\n",
        "#   print np.column_stack((pred_Y[i],Y_test[i]))\n",
        "\n",
        "# Create linear regression object\n",
        "#regr1 = linear_model.Ridge(alpha=10.0)\n",
        "regr1 = linear_model.RidgeCV(alphas=np.logspace(-3, 5, 9),fit_intercept=True,cv=2)\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr1.fit(X_train, Y_train)\n",
        "pred_Y_ridge = regr1.predict(X_test)\n",
        "\n",
        "\n",
        "# Create linear regression object\n",
        "#regr2 = linear_model.Lasso(alpha=0.35)\n",
        "regr2 = linear_model.LassoCV(alphas=np.logspace(-3, 5, 9),cv=2)\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr2.fit(X_train, Y_train)\n",
        "pred_Y_lasso = regr2.predict(X_test)\n",
        "\n",
        "# The coefficients\n",
        "print('Coefficients - Linear Regression: \\n', regr.coef_)\n",
        "print('Coefficients - Ridge: \\n', regr1.coef_)\n",
        "print('Coefficients - Lasso: \\n', regr2.coef_)\n",
        "\n",
        "print('Intercept - Linear Regression: \\n', regr.intercept_)\n",
        "print('Intercept - Ridge: \\n', regr1.intercept_)\n",
        "print('Intercept - Lasso: \\n', regr2.intercept_)\n",
        "\n",
        "print(\"Alphas from Cross Validation: ridge_alpha: %f, lasso_alpha: %f\" %(regr1.alpha_, regr2.alpha_))\n",
        "\n",
        "#for i in np.arange(0,Y_test.shape[0]):\n",
        "#   print np.column_stack((pred_Y[i],pred_Y_ridge[i], pred_Y_lasso[i], Y_test[i]))\n",
        "\n",
        "print(\"MSE, Validation; Linear Reg : %.2f, Ridge : %.2f, Lasso : %.2f\"\n",
        "      % (mean_squared_error(pred_Y, Y_test), mean_squared_error(pred_Y_ridge, Y_test), mean_squared_error(pred_Y_lasso, Y_test)))\n",
        "############################################################\n",
        "# Predicting Test Data\n",
        "############################################################\n",
        "\n",
        "test_set = ['TEST_S01_T01.csv', 'TEST_S02_T02.csv', 'TEST_S04_T02.csv', 'TEST_S06_T01.csv', 'TEST_S07_T02.csv', 'TEST_S02_T01.csv', 'TEST_S03_T02.csv', 'TEST_S05_T02.csv', 'TEST_S06_T02.csv', 'TEST_S08_T01.csv']\n",
        "true_test_set = ['True_S01_T01.csv', 'True_S02_T02.csv', 'True_S04_T02.csv', 'True_S06_T01.csv', 'True_S07_T02.csv', 'True_S02_T01.csv', 'True_S03_T02.csv', 'True_S05_T02.csv', 'True_S06_T02.csv', 'True_S08_T01.csv']\n",
        "#test_set = ['TEST_S01_T01.csv', 'TEST_S02_T02.csv', 'TEST_S04_T02.csv', 'TEST_S06_T01.csv', 'TEST_S07_T02.csv']\n",
        "#true_test_set = ['True_S01_T01.csv', 'True_S02_T02.csv', 'True_S04_T02.csv', 'True_S06_T01.csv', 'True_S07_T02.csv']\n",
        "#test_set = ['TEST_S03_T02.csv']\n",
        "#true_test_set = ['True_S03_T02.csv']\n",
        "test_dir_path =  './ML_SP_GAN/ppg_test_data_csv/TestData/' #'/content/gdrive/My Drive/ML_SP_PESIT/ml-course-code-may14/ml-course-code/ppg_test_data_csv/TestData/' #'../ppg_test_data_csv/TestData/'\n",
        "true_test_dir_path = './ML_SP_GAN/ppg_test_data_csv/TrueBPM/' #'/content/gdrive/My Drive/ML_SP_PESIT/ml-course-code-may14/ml-course-code/ppg_test_data_csv/TrueBPM/' # '../ppg_test_data_csv/TrueBPM/'\n",
        "for file_ind in np.arange(0,len(test_set)):\n",
        "   print (test_set[file_ind])\n",
        "   #print true_test_set[file_ind]\n",
        "   filepath = test_dir_path+test_set[file_ind]\n",
        "   \n",
        "   #Load training data from a file\n",
        "   data = np.loadtxt(open(filepath, \"rb\"), delimiter=\",\")\n",
        "   #print data.shape\n",
        "   \n",
        "   datalen = data.shape[0]  #Total length of data\n",
        "   #Indexes to split a single array into matrix. A single BPM is computed over an interval of 8s (1000 samples). \n",
        "   #The next number over another 8s window starting at an offset of 2s (500 samples) from previous window\n",
        "\n",
        "   index_arr = np.arange(0, datalen-numsampleswin+1, freq*dataoffsetinsec)  \n",
        "   datax=np.zeros(shape=(index_arr.shape[0], numsampleswin, 5),dtype=np.float)\n",
        "   for j in np.arange(0,5):\n",
        "    for i in range(index_arr.shape[0]): datax[i,:,j] = data[index_arr[i]:numsampleswin+index_arr[i], j]\n",
        "\n",
        "   #print datax.shape\n",
        "   \n",
        "   #X = np.column_stack((np.ones([index_arr.shape[0],1], dtype=float), features_2(datax)))\n",
        "   X = features_2(datax)\n",
        "   X = normalize(X, norm='l2', axis=0, return_norm=False)\n",
        "\n",
        "   outfilepath = true_test_dir_path+true_test_set[file_ind]\n",
        "   #Load output training data from a file\n",
        "   trueY = np.loadtxt(open(outfilepath, \"rb\"), delimiter=\",\")\n",
        "   #print trueY.shape\n",
        "\n",
        "   pred_test_Y       = regr.predict(X)\n",
        "   pred_test_Y_ridge = regr1.predict(X)\n",
        "   pred_test_Y_lasso = regr2.predict(X)\n",
        "   print(\"MSE, Test Linear Reg : %.2f, Ridge : %.2f, Lasso : %.2f\"\n",
        "      % (mean_squared_error(pred_test_Y, trueY), mean_squared_error(pred_test_Y_ridge, trueY), mean_squared_error(pred_test_Y_lasso, trueY)))\n",
        "   \n",
        "   #for i in np.arange(0,trueY.shape[0]):\n",
        "   #   print np.column_stack((pred_test_Y[i], pred_test_Y_ridge[i], pred_test_Y_lasso[i], trueY[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1620,)\n",
            "(1620, 75)\n",
            "Coefficients - Linear Regression: \n",
            " [-2.79436588e+00  2.74522070e+01 -4.37423942e+01  2.43599477e+03\n",
            " -2.59312106e+02  8.43613236e+00  2.81170581e+01 -2.05211973e+01\n",
            " -3.79984413e+03  2.82870768e+02 -6.56552417e-01 -9.11513251e+00\n",
            " -1.18842924e+01  1.81408466e+03 -2.42045836e+02  8.65821074e+01\n",
            "  7.54466588e+01 -5.58168588e+01  3.90076353e+02  2.19031872e+02\n",
            " -6.83245497e+00  1.12498331e+01  1.05030007e+01 -1.40421488e+01\n",
            "  1.72360164e+01  1.14881427e+01 -4.85902826e+00  2.57949172e+00\n",
            "  6.28007297e+00 -2.82248783e-01  9.56243749e+00 -1.27648182e+01\n",
            "  6.07771785e+00  1.09764605e+01  2.28338693e+00 -1.51406653e+02\n",
            " -1.10054143e+02 -1.89369247e+02 -5.71403411e+01  5.88953293e+01\n",
            " -9.11506153e+00  1.71570333e+01 -1.73646416e+01 -5.28890109e+00\n",
            " -3.29307716e+00  3.66923869e+00 -3.28453035e+00 -2.49722481e+00\n",
            "  1.86331460e+01 -6.04306173e+00  1.27017668e+01 -5.04752832e+00\n",
            "  1.69752805e+01  2.10239848e+01 -7.27026783e+00  1.08441688e+02\n",
            "  3.08244783e+00 -1.13150235e+01 -1.32154707e+02  3.82940015e+01\n",
            " -2.98628263e+02 -1.53311694e+02  1.75282835e+02 -5.97756479e+02\n",
            " -1.04301075e+02  4.54111218e+02  3.34268634e+02  3.48933279e+02\n",
            " -3.48793910e+02  1.56633155e+02  2.97273252e+01 -3.54813724e+02\n",
            "  2.68871282e+02  4.26221915e+02 -3.65835186e+02]\n",
            "Coefficients - Ridge: \n",
            " [  3.76959837   9.30605083 -11.20914624   5.59920842 -19.79653235\n",
            "   1.40918595   5.75896814  16.09657353   7.23170088 -20.43024179\n",
            "   2.79957089   7.96325647 -14.97911865   7.96809569 -23.27933331\n",
            "  13.41164039  12.06325996   2.0487242    7.66666727   3.82252756\n",
            "  -0.41035589   1.30379404   2.96037626  -4.40508766   5.52207798\n",
            "  11.6537391    1.21440915   8.01672263   3.46006445   3.75164525\n",
            "   2.25098266  -3.21369224   3.50227062   0.30750759   4.2684468\n",
            "  16.15034835   8.83028928   6.21800121   7.64919221  11.0652554\n",
            "  -0.0854807    2.66868644  -3.65899358   1.18960175   0.20279033\n",
            "   8.78087843   2.78387148   5.14411619   4.83529563  -0.06426151\n",
            "   2.56963493   1.25716776   3.31255875   2.67631885  -0.89765737\n",
            "   5.92198402   1.60216858   7.66494508   0.04676872   8.03635786\n",
            "  16.56891887  11.01791099  11.97241792   7.08165532   9.77202748\n",
            "  20.41134382  12.95805428  13.19178422   8.50466211   9.47103069\n",
            "   9.07243904   4.46213569   9.46173846   9.58192379   7.93720322]\n",
            "Coefficients - Lasso: \n",
            " [  0.           0.          -0.           0.         -47.68156157\n",
            "  -0.           0.           6.77808838   0.          -0.\n",
            "   0.           9.65678257 -37.6372146    0.         -59.34264936\n",
            "   0.           0.           0.           0.           0.\n",
            "   0.           0.           0.          -0.           0.\n",
            "   4.96614156   0.           2.28777829   0.           0.\n",
            "   0.          -0.           0.          -0.           0.\n",
            "   0.           0.           0.           0.           4.59001531\n",
            "   0.           0.          -0.           0.          -0.\n",
            "   0.           0.           0.           0.           0.\n",
            "   0.           0.           0.           0.          -0.\n",
            "   0.           0.           0.           0.           0.\n",
            "   0.           0.           0.           0.           0.\n",
            " 147.47700109   0.          74.52532308   0.           0.\n",
            "   0.           0.           0.           0.           0.        ]\n",
            "Intercept - Linear Regression: \n",
            " 84.81922705408569\n",
            "Intercept - Ridge: \n",
            " 110.73986701167485\n",
            "Intercept - Lasso: \n",
            " 121.0109996984009\n",
            "Alphas from Cross Validation: ridge_alpha: 10.000000, lasso_alpha: 0.100000\n",
            "MSE, Validation; Linear Reg : 306.44, Ridge : 278.49, Lasso : 233.37\n",
            "TEST_S01_T01.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 107.38554202401428, tolerance: 36.746030311966926\n",
            "  tol, rng, random, positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 116.14150917960797, tolerance: 44.99337475515373\n",
            "  tol, rng, random, positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MSE, Test Linear Reg : 221046.99, Ridge : 3058.76, Lasso : 3340.76\n",
            "TEST_S02_T02.csv\n",
            "MSE, Test Linear Reg : 486875.16, Ridge : 463.43, Lasso : 395.41\n",
            "TEST_S04_T02.csv\n",
            "MSE, Test Linear Reg : 1039.99, Ridge : 490.43, Lasso : 355.87\n",
            "TEST_S06_T01.csv\n",
            "MSE, Test Linear Reg : 101314.92, Ridge : 1828.05, Lasso : 1803.44\n",
            "TEST_S07_T02.csv\n",
            "MSE, Test Linear Reg : 547852.20, Ridge : 80.90, Lasso : 81.02\n",
            "TEST_S02_T01.csv\n",
            "MSE, Test Linear Reg : 151095.83, Ridge : 3006.78, Lasso : 3105.73\n",
            "TEST_S03_T02.csv\n",
            "MSE, Test Linear Reg : 504579.99, Ridge : 1194.47, Lasso : 973.98\n",
            "TEST_S05_T02.csv\n",
            "MSE, Test Linear Reg : 218491.49, Ridge : 143.94, Lasso : 87.40\n",
            "TEST_S06_T02.csv\n",
            "MSE, Test Linear Reg : 452348.70, Ridge : 328.33, Lasso : 240.71\n",
            "TEST_S08_T01.csv\n",
            "MSE, Test Linear Reg : 537943.61, Ridge : 2404.16, Lasso : 2336.49\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}